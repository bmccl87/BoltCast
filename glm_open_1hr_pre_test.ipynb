{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import os \n",
    "import shutil \n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pygrib\n",
    "import pickle\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from util import boxbin \n",
    "\n",
    "#################################################################\n",
    "# Default plotting parameters\n",
    "FIGURESIZE=(10,6)\n",
    "FONTSIZE=  18\n",
    "plt.rcParams['figure.figsize'] = FIGURESIZE\n",
    "plt.rcParams['font.size'] = FONTSIZE\n",
    "plt.rcParams['xtick.labelsize'] = FONTSIZE\n",
    "plt.rcParams['ytick.labelsize'] = FONTSIZE\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#set the storage directory\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m glm_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/ourdisk/hpc/ai2es/bmac87/OG_datasets/GLM/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/flashes_GE/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(\u001b[43msat\u001b[49m,yr)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#load the gfs grid\u001b[39;00m\n\u001b[1;32m      5\u001b[0m static_inputs \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Archive/static_inputs.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sat' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load the gfs grid\n",
    "static_inputs = pickle.load(open('./Archive/static_inputs.pkl','rb'))\n",
    "lat = static_inputs['lat']#2D\n",
    "lon = static_inputs['lon']#2D\n",
    "\n",
    "\n",
    "#add the next grid point so the binning algorithm \n",
    "#size is 256x128\n",
    "bin_lat = np.concatenate([lat[:,0],[53.25]])\n",
    "bin_lon = np.concatenate([lon[0,:],[298]])\n",
    "\n",
    "#store the sorted grid\n",
    "xedge = np.sort(bin_lon)\n",
    "yedge = np.sort(bin_lat)\n",
    "\n",
    "xmid = [] #Blank array\n",
    "ymid = [] #Blank array\n",
    "\n",
    "#calcuate the midpoints for the sorting algorithm\n",
    "i=0\n",
    "while(i < len(xedge)-1):\n",
    "    xmid.append((xedge[i]+xedge[i+1])/2) #Calculate and append midpoints\n",
    "    i+=1 \n",
    "i=0\n",
    "while(i < len(yedge)-1):\n",
    "    ymid.append((yedge[i]+yedge[i+1])/2) #Calculate and append midpoints\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019 002 00\n",
      "2019 002 01\n",
      "2019 002 02\n",
      "2019 002 03\n",
      "2019 002 04\n",
      "2019 002 05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f,file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(hr_files):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m         ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m         ds \u001b[38;5;241m=\u001b[39m ds[ltg_vars] \u001b[38;5;66;03m#get the flash information using the dataset variables\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         df \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mto_dataframe() \u001b[38;5;66;03m#convert to dataframe\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pygrib/lib/python3.12/site-packages/xarray/backends/api.py:571\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    560\u001b[0m     decode_cf,\n\u001b[1;32m    561\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    568\u001b[0m )\n\u001b[1;32m    570\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 571\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    578\u001b[0m     backend_ds,\n\u001b[1;32m    579\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    590\u001b[0m )\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.conda/envs/pygrib/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:660\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    658\u001b[0m store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n\u001b[0;32m--> 660\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mstore_entrypoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_and_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_and_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_times\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcat_characters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcat_characters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cftime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cftime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_timedelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_timedelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/.conda/envs/pygrib/lib/python3.12/site-packages/xarray/backends/store.py:43\u001b[0m, in \u001b[0;36mStoreBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     31\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     decode_timedelta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename_or_obj, AbstractDataStore)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28mvars\u001b[39m, attrs \u001b[38;5;241m=\u001b[39m \u001b[43mfilename_or_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m filename_or_obj\u001b[38;5;241m.\u001b[39mget_encoding()\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mvars\u001b[39m, attrs, coord_names \u001b[38;5;241m=\u001b[39m conventions\u001b[38;5;241m.\u001b[39mdecode_cf_variables(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28mvars\u001b[39m,\n\u001b[1;32m     48\u001b[0m         attrs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[1;32m     56\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/pygrib/lib/python3.12/site-packages/xarray/backends/common.py:251\u001b[0m, in \u001b[0;36mAbstractDataStore.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    230\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    This loads the variables and attributes simultaneously.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    A centralized loading function makes it easier to create\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m    are requested, so care should be taken to make sure its fast.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     variables \u001b[38;5;241m=\u001b[39m FrozenDict(\n\u001b[0;32m--> 251\u001b[0m         (_decode_variable_name(k), v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    252\u001b[0m     )\n\u001b[1;32m    253\u001b[0m     attributes \u001b[38;5;241m=\u001b[39m FrozenDict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_attrs())\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m variables, attributes\n",
      "File \u001b[0;32m~/.conda/envs/pygrib/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:462\u001b[0m, in \u001b[0;36mNetCDF4DataStore.get_variables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_variables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFrozenDict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_store_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pygrib/lib/python3.12/site-packages/xarray/core/utils.py:443\u001b[0m, in \u001b[0;36mFrozenDict\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFrozenDict\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Frozen:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Frozen(\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/pygrib/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:463\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_variables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FrozenDict(\n\u001b[0;32m--> 463\u001b[0m         (k, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_store_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    464\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/pygrib/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:425\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open_store_variable\u001b[0;34m(self, name, var)\u001b[0m\n\u001b[1;32m    423\u001b[0m dimensions \u001b[38;5;241m=\u001b[39m var\u001b[38;5;241m.\u001b[39mdimensions\n\u001b[1;32m    424\u001b[0m attributes \u001b[38;5;241m=\u001b[39m {k: var\u001b[38;5;241m.\u001b[39mgetncattr(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m var\u001b[38;5;241m.\u001b[39mncattrs()}\n\u001b[0;32m--> 425\u001b[0m data \u001b[38;5;241m=\u001b[39m indexing\u001b[38;5;241m.\u001b[39mLazilyIndexedArray(\u001b[43mNetCDF4ArrayWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    426\u001b[0m encoding: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(var\u001b[38;5;241m.\u001b[39mdatatype, netCDF4\u001b[38;5;241m.\u001b[39mEnumType):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#set the satellite and year\n",
    "sat = 'G16'\n",
    "yr = '2019'\n",
    "hr = '12'\n",
    "\n",
    "\n",
    "\n",
    "#declare the coordinates you need from the glm data raw files\n",
    "coords = ['flash_lat','flash_lon','flash_id','flash_time_offset_of_first_event']\n",
    "ltg_vars = ['flash_area','flash_energy','flash_quality_flag']\n",
    "df_cols = np.concatenate([coords,ltg_vars])\n",
    "\n",
    "save_dir = '/ourdisk/hpc/ai2es/bmac87/OG_datasets/GLM/'+sat+'/flashes_1hr_df/'\n",
    "hours = ['00','01','02','03','04','05','06','07','08','09','10','11','12',\n",
    "        '13','14','15','16','17','18','19','20','21','22','23']\n",
    "\n",
    "for yr in ['2019','2020','2021','2022','2023','2024']: \n",
    "    #build the array of julian days. add 366 for leap year\n",
    "    j_days = []\n",
    "    for i in range(1,366):\n",
    "        j_days.append(f\"{i:03}\")\n",
    "    if yr=='2020':\n",
    "        j_days.append('366')\n",
    "\n",
    "    #loop through the files\n",
    "    for d,day in enumerate(j_days):\n",
    "        if d>=1:\n",
    "            og_nc_dir = '/ourdisk/hpc/ai2es/bmac87/OG_datasets/GLM/'+sat+'/'+yr+'/'+day+'/'\n",
    "            og_nc_files = sorted(os.listdir(og_nc_dir))\n",
    "            for h,hr in enumerate(hours):\n",
    "                print(yr,day,hr)\n",
    "                if h>=0:\n",
    "\n",
    "                    #OR_GLM-L2-LCFA_G16_s20190010000000_e20190010000200_c20190010000227.nc\n",
    "                    hr_files = sorted(glob.glob(og_nc_dir+'OR_GLM-L2-LCFA_'+sat+'_s'+yr+day+hr+'*.nc'))\n",
    "                    for f,file in enumerate(hr_files):\n",
    "                        try:\n",
    "                            ds = xr.open_dataset(file)\n",
    "                            ds = ds[ltg_vars] #get the flash information using the dataset variables\n",
    "                            df = ds.to_dataframe() #convert to dataframe\n",
    "                            df.index = df['flash_time_offset_of_first_event']#set the indices\n",
    "                            df = df[df_cols] #subset the flash information with Lat/Lon\n",
    "                            \n",
    "                            if f==0:\n",
    "                                flashes_df = df\n",
    "                            else:\n",
    "                                flashes_df = pd.concat([flashes_df,df])\n",
    "                        #end try\n",
    "\n",
    "                        except FileNotFoundError:\n",
    "                            print(file, 'file not found')\n",
    "                        #end_except\n",
    "\n",
    "                    #end_for_files\n",
    "                    if not os.path.isdir(save_dir):\n",
    "                        os.mkdirs(save_dir)\n",
    "                    pickle.dump(flashes_df,open(save_dir+sat+'_'+yr+'_'+day+'_'+hr+'.pkl','wb'))\n",
    "                    del flashes_df, df, ds\n",
    "                #end_hours_test\n",
    "            #end_for_hours\n",
    "        #end_days_test\n",
    "    #end_for_days\n",
    "#end_for_yrs\n",
    "\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pickle output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flash_lat</th>\n",
       "      <th>flash_lon</th>\n",
       "      <th>flash_id</th>\n",
       "      <th>flash_time_offset_of_first_event</th>\n",
       "      <th>flash_area</th>\n",
       "      <th>flash_energy</th>\n",
       "      <th>flash_quality_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash_time_offset_of_first_event</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:00:00.382239341</th>\n",
       "      <td>-36.582981</td>\n",
       "      <td>-60.864941</td>\n",
       "      <td>21511</td>\n",
       "      <td>2019-01-01 15:00:00.382239341</td>\n",
       "      <td>67.907829</td>\n",
       "      <td>3.204537e-14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:00:00.513085365</th>\n",
       "      <td>-38.438507</td>\n",
       "      <td>-63.527039</td>\n",
       "      <td>21512</td>\n",
       "      <td>2019-01-01 15:00:00.513085365</td>\n",
       "      <td>69.739052</td>\n",
       "      <td>9.155820e-15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:00:00.122454643</th>\n",
       "      <td>-32.107563</td>\n",
       "      <td>-57.497242</td>\n",
       "      <td>21510</td>\n",
       "      <td>2019-01-01 15:00:00.122454643</td>\n",
       "      <td>975.736328</td>\n",
       "      <td>8.499653e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:00:00.743115425</th>\n",
       "      <td>-30.705791</td>\n",
       "      <td>-59.289330</td>\n",
       "      <td>21513</td>\n",
       "      <td>2019-01-01 15:00:00.743115425</td>\n",
       "      <td>73.248894</td>\n",
       "      <td>1.068179e-14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:00:01.204319477</th>\n",
       "      <td>-29.417583</td>\n",
       "      <td>-57.866787</td>\n",
       "      <td>21514</td>\n",
       "      <td>2019-01-01 15:00:01.204319477</td>\n",
       "      <td>290.096161</td>\n",
       "      <td>1.419152e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:59:58.806747436</th>\n",
       "      <td>-31.078432</td>\n",
       "      <td>-58.951519</td>\n",
       "      <td>44724</td>\n",
       "      <td>2019-01-01 15:59:58.806747436</td>\n",
       "      <td>493.972260</td>\n",
       "      <td>7.477253e-14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:59:59.057758331</th>\n",
       "      <td>-38.623978</td>\n",
       "      <td>-62.729149</td>\n",
       "      <td>44725</td>\n",
       "      <td>2019-01-01 15:59:59.057758331</td>\n",
       "      <td>140.241119</td>\n",
       "      <td>1.068179e-14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:59:59.202339172</th>\n",
       "      <td>-18.332787</td>\n",
       "      <td>-57.272587</td>\n",
       "      <td>44728</td>\n",
       "      <td>2019-01-01 15:59:59.202339172</td>\n",
       "      <td>149.397232</td>\n",
       "      <td>2.441552e-14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:59:59.216453552</th>\n",
       "      <td>-28.749537</td>\n",
       "      <td>-56.672192</td>\n",
       "      <td>44729</td>\n",
       "      <td>2019-01-01 15:59:59.216453552</td>\n",
       "      <td>651.457397</td>\n",
       "      <td>3.631809e-13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:59:59.451061248</th>\n",
       "      <td>-29.402369</td>\n",
       "      <td>-57.373684</td>\n",
       "      <td>44732</td>\n",
       "      <td>2019-01-01 15:59:59.451061248</td>\n",
       "      <td>145.276978</td>\n",
       "      <td>1.373373e-14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15010 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  flash_lat  flash_lon  flash_id  \\\n",
       "flash_time_offset_of_first_event                                   \n",
       "2019-01-01 15:00:00.382239341    -36.582981 -60.864941     21511   \n",
       "2019-01-01 15:00:00.513085365    -38.438507 -63.527039     21512   \n",
       "2019-01-01 15:00:00.122454643    -32.107563 -57.497242     21510   \n",
       "2019-01-01 15:00:00.743115425    -30.705791 -59.289330     21513   \n",
       "2019-01-01 15:00:01.204319477    -29.417583 -57.866787     21514   \n",
       "...                                     ...        ...       ...   \n",
       "2019-01-01 15:59:58.806747436    -31.078432 -58.951519     44724   \n",
       "2019-01-01 15:59:59.057758331    -38.623978 -62.729149     44725   \n",
       "2019-01-01 15:59:59.202339172    -18.332787 -57.272587     44728   \n",
       "2019-01-01 15:59:59.216453552    -28.749537 -56.672192     44729   \n",
       "2019-01-01 15:59:59.451061248    -29.402369 -57.373684     44732   \n",
       "\n",
       "                                 flash_time_offset_of_first_event  flash_area  \\\n",
       "flash_time_offset_of_first_event                                                \n",
       "2019-01-01 15:00:00.382239341       2019-01-01 15:00:00.382239341   67.907829   \n",
       "2019-01-01 15:00:00.513085365       2019-01-01 15:00:00.513085365   69.739052   \n",
       "2019-01-01 15:00:00.122454643       2019-01-01 15:00:00.122454643  975.736328   \n",
       "2019-01-01 15:00:00.743115425       2019-01-01 15:00:00.743115425   73.248894   \n",
       "2019-01-01 15:00:01.204319477       2019-01-01 15:00:01.204319477  290.096161   \n",
       "...                                                           ...         ...   \n",
       "2019-01-01 15:59:58.806747436       2019-01-01 15:59:58.806747436  493.972260   \n",
       "2019-01-01 15:59:59.057758331       2019-01-01 15:59:59.057758331  140.241119   \n",
       "2019-01-01 15:59:59.202339172       2019-01-01 15:59:59.202339172  149.397232   \n",
       "2019-01-01 15:59:59.216453552       2019-01-01 15:59:59.216453552  651.457397   \n",
       "2019-01-01 15:59:59.451061248       2019-01-01 15:59:59.451061248  145.276978   \n",
       "\n",
       "                                  flash_energy  flash_quality_flag  \n",
       "flash_time_offset_of_first_event                                    \n",
       "2019-01-01 15:00:00.382239341     3.204537e-14                 0.0  \n",
       "2019-01-01 15:00:00.513085365     9.155820e-15                 0.0  \n",
       "2019-01-01 15:00:00.122454643     8.499653e-13                 0.0  \n",
       "2019-01-01 15:00:00.743115425     1.068179e-14                 0.0  \n",
       "2019-01-01 15:00:01.204319477     1.419152e-13                 0.0  \n",
       "...                                        ...                 ...  \n",
       "2019-01-01 15:59:58.806747436     7.477253e-14                 0.0  \n",
       "2019-01-01 15:59:59.057758331     1.068179e-14                 0.0  \n",
       "2019-01-01 15:59:59.202339172     2.441552e-14                 0.0  \n",
       "2019-01-01 15:59:59.216453552     3.631809e-13                 0.0  \n",
       "2019-01-01 15:59:59.451061248     1.373373e-14                 0.0  \n",
       "\n",
       "[15010 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr = '15'\n",
    "day ='001'\n",
    "yr='2019'\n",
    "\n",
    "df = pickle.load(open(save_dir+sat+'_'+yr+'_'+day+'_'+hr+'.pkl','rb'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # print(og_nc_files[0])\n",
    "        # print(og_nc_files[-1])\n",
    "        # for nc_file in og_nc_files:\n",
    "        #     print(nc_file)\n",
    "\n",
    "\n",
    "\n",
    "    # try:\n",
    "    #     ds = xr.open_dataset(glm_dir+glm_file,engine='netcdf4')\n",
    "    #     df = ds.to_dataframe()\n",
    "    # except FileNotFoundError:\n",
    "    #     print('no file',glm_dir+glm_file)\n",
    "    #     continue\n",
    "        \n",
    "    #     df['date_time'] = df.index\n",
    "    #     days = df['date_time'].dt.day.drop_duplicates().values\n",
    "    #     df_last_day = df.loc[((df['date_time'].dt.day==days[0]))]\n",
    "\n",
    "    #     hours = np.linspace(0,23,24)\n",
    "    #     for hour in hours:\n",
    "#             if hour==0:\n",
    "#                 df_1hr = pd.concat([df_last_day,df.loc[((df['date_time'].dt.hour==hour))]])\n",
    "#             elif hour==23:\n",
    "#                 df_1hr = df.loc[((df['date_time'].dt.day==days[1]))]\n",
    "#                 df_1hr = df_1hr.loc[(df_1hr['date_time'].dt.hour==hour)]\n",
    "#             else:\n",
    "#                 df_1hr = df.loc[((df['date_time'].dt.hour==hour))]\n",
    "# df_1hr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygrib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
